Abstract— Neural networks have revolutionized artificial intelligence but remain largely black-box systems with fixed-weight architectures. This paper introduces Ψ-Sai Net, a novel adaptive neural network framework that dynamically adjusts its weights based on learned real-world context, integrating Ψ-stability factors and context-aware modulation. Unlike traditional deep learning models and transformers, Ψ-Sai Net continuously adapts to changing external conditions—such as economic uncertainty, risk fluctuations, or environmental variations—without requiring retraining. By employing Sai Numbers (Ψ-Sai) for context-driven learning and RNN-based external context evaluation, the model autonomously refines its internal parameters, ensuring enhanced stability and interpretability. Furthermore, we propose a Ψ-Sai Decomposition technique, making the decision-making process mathematically transparent at the neuron level. Benchmark experiments demonstrate that Ψ-Sai Net outperforms conventional models in adaptive decision-making tasks, particularly in real-world applications such as financial forecasting, autonomous systems, and risk assessment. Our findings suggest that Ψ-Sai Net provides a paradigm shift towards white-box, self-adaptive neural networks, paving the way for more reliable, interpretable, and efficient AI architectures.

Keywords— Ψ-Sai Net, Adaptive Neural Networks, Context-Aware Learning, Dynamic Weight Adjustment, Explainable AI (XAI), Stability-Aware AI, Ψ-Sai Decomposition, RNN-Modulated Adaptation.

